{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "\n",
    "weights = ResNet18_Weights.DEFAULT\n",
    "preprocessing = weights.transforms()  # incluye el data augmentation realizado (resize and crop).\n",
    "# original_classes_names = weights.meta['categories']\n",
    "\n",
    "net = resnet18(weights=weights)\n",
    "\n",
    "# Sustitución del clasificador:\n",
    "n_classes = 10\n",
    "num_ft = net.fc.in_features\n",
    "net.fc = nn.Linear(num_ft, n_classes)\n",
    "\n",
    "# Optimizador (todos los parámetros serán actualizados):\n",
    "optimizer = SGD(net.parameters(), lr=1e-3, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "\n",
    "weights = ResNet18_Weights.DEFAULT\n",
    "preprocessing = weights.transforms()\n",
    "# original_classes_names = weights.meta['categories']\n",
    "\n",
    "net = resnet18(weights=weights)\n",
    "\n",
    "# Congelar todos los parámetros:\n",
    "for param in net.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Sustitución del clasificador:\n",
    "n_classes = 10\n",
    "num_ft = net.fc.in_features\n",
    "net.fc = nn.Linear(num_ft, n_classes)  # por default, requires_grad = True.\n",
    "\n",
    "# Optimizador (solo los parámetros del clasificador final se actualizarán):\n",
    "optimizer = SGD(net.fc.parameters(), lr=1e-3, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuando se están actualizando varias capas o fragmentos de un Sequential se deben guardar\n",
    "# en una lista los parámetros que se actualizarán (solo los que tiene requires_grad = True):\n",
    "\n",
    "print('Parámetros que se actualizarán:')\n",
    "params_to_update = []\n",
    "for name, param in net.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        print('\\t', name)\n",
    "\n",
    "optimizer = SGD(params_to_update, lr=1e-3, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otras arquitecturas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AlexNet:\n",
    "# El clasificador (net.classifier) es un Sequential de módulos FC. El último módulo (6) es el clasificador final.\n",
    "# Por lo tanto, se debe realizar lo siguiente:\n",
    "net.classifier[6] = nn.Linear(4096, n_classes)\n",
    "\n",
    "# VGG:\n",
    "# Ocurre lo mismo que en AlexNet, la capa FC final está en la posición 6:\n",
    "net.classifier[6] = nn.Linear(4096, n_classes)\n",
    "\n",
    "# SqueezeNet (1.0):\n",
    "# El clasificador es un Sequential de dropout -> conv2d (clasificador) -> relu -> avgpool.\n",
    "# Por lo tanto, se debe modificar la capa convolucional:\n",
    "net.classifier[1] = nn.Conv2d(512, n_classes, kernel_size=(1,1), stride=(1,1))\n",
    "\n",
    "# DenseNet-121:\n",
    "# El clasificador es un módulo simple (no Sequential), por lo tanto:\n",
    "net.classifier = nn.Linear(1024, n_classes)\n",
    "\n",
    "# Inception v3:\n",
    "# Contiene dos salidas por lo que se deben modificar dos capas:\n",
    "net.AuxLogits.fc = nn.Linear(768, n_classes)\n",
    "net.fc = nn.Linear(2048, n_classes)\n",
    "\n",
    "# Solo se usa la salida final en testing. Para training, se deben ponderar las losses.\n",
    "# Se debe modificar el trainer agregando el siguiente fragmento:\n",
    "if is_inception and mode == 'train':\n",
    "    output, aux_output = net(x)\n",
    "    loss1 = loss_fn(output, y)\n",
    "    loss2 = loss_fn(aux_output, y)\n",
    "    loss = loss1 + 0.4*loss2\n",
    "\n",
    "# En general, basta imprimir el modelo para saber qué capas deben ser modificadas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
